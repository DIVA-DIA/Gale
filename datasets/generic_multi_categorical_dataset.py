"""
Load a dataset of images by specifying the folder where its located.
"""

import logging
# Utils
import os
from collections import Counter

import numpy as np
import pandas as pd
# Torch related stuff
import torch.utils.data as data
import torchvision
from torchvision.datasets.folder import pil_loader


class MultiCategoricalDataset(data.Dataset):
    """This class loads the multi-label image data provided"""

    # List(str) of all categories names
    categories = None
    # Dict{str:list} where at each 'category' correspond a list of all classes into it
    classes = None
    # Dict{str:int}  where at each 'category' correspond the number of classes in it
    num_classes = None
    # Dict{str:list} where at each 'category' correspond a dict{class_name:count}
    frequencies = None

    def __init__(self, path, transform=None, target_transform=None, categories=None, **kwargs):
        """
        Load the data and prepares it as a dataset.

        Parameters
        ----------
        path : string
            Path to the dataset on the file System
        transform : torchvision.transforms
            Transformation to apply on the data
        target_transform : torchvision.transforms
            Transformation to apply on the labels
        categories : list(str)
            List of names for each category e.g. "type", "dishware", "format", ...
        """
        self.dataset_folder = os.path.expanduser(path)
        self.transform = transform
        self.target_transform = target_transform

        # Read the labels.csv
        df = pd.read_csv(os.path.join(self.dataset_folder, 'labels.csv'), header=None)

        # Shuffle the data once (otherwise you get clusters of samples of same class combination in each minibatch for val and test)
        df = df.sample(frac=1).reset_index(drop=True)

        # Get file names from left-most column
        self.filenames = df.values[:, 0]
        self.filenames = [os.path.join(self.dataset_folder, 'images', f"{item}.jpg") for item in self.filenames]

        self.update_dataset_statistics(categories, df, path)

        # Store the actual values
        self.values = df.values[:, 1:]

    @classmethod
    def update_dataset_statistics(cls, categories, df, path):
        # If first time, assign categories
        if cls.categories is None:
            cls.categories = categories if categories is not None else [str(i) for i in range(df.values.shape[1] - 1)]
        assert len(cls.categories) == df.values.shape[1] - 1

        # If first time, get frequencies of the labels for each category (this is supposedly run on the training split!)
        if cls.frequencies is None:
            cls.frequencies = {}
            for i, cat in enumerate(categories):
                cls.frequencies[cat] = {str(k): v for k, v in Counter(df.values[:, i + 1]).items()}

        # Create the sorted list of classes found in this split
        split_classes = {}
        for i, cat in enumerate(categories):
            split_classes[cat] = list(np.unique(np.array(df.values[:, i + 1], dtype=str)))

        # Updates everything if necessary
        if cls.classes is None:
            cls.classes = split_classes
        else:
            # The categories must be the same
            assert len(cls.classes) == len(split_classes)
            # Verify that they contain the same classes, if not, log and merge whereas appropriate
            for c in categories:
                mcatd_set = set(cls.classes[c])
                split_set = set(split_classes[c])
                # MISSING classes in this split
                diff = list(mcatd_set - split_set)
                if len(diff) > 0:
                    logging.warning(f"There are missing classes ({c} > {diff}) not found in {path}")
                # EXTRA classes in this split
                diff = list(split_set - mcatd_set)
                if len(diff) > 0:
                    logging.error(f"There are extra classes ({c} > {diff}) found in {path}")
                    cls.classes[c].extend(diff)
                    cls.classes[c].sort()
                    cls.frequencies[c].update({d: float('NaN') for d in diff})

        # Compute the number of classes on the update classes dict
        cls.num_classes = {k: len(v) for k, v in cls.classes.items()}

    @classmethod
    def get_weights(cls):
        weights = {}
        for category in cls.categories:
            # Get inverse of frequencies in same order of class names (sorted alphabetically)
            weights[category] = [1 / cls.frequencies[category][c] for c in cls.classes[category]]
            # Remove 'NaN' generated by missing classes in the train set and set them to '0'
            weights[category] = np.nan_to_num(weights[category])
            # Normalise to sum up to 1
            weights[category] /= np.array(weights[category]).sum()
        return weights

    @classmethod
    def _name_to_idx(cls, category: str, class_name):
        """
        Convert a class name gives as string to a numerical index appropriate for the category provided

        Parameters
        ----------
        category : str
            Category from which convert the class name
        class_name : float or str
            Class name to resolve

        Returns
        -------
        class_idx :  int
            Index of that class in the chosen category. Keep in mind class names are sorted alphabetically
        """
        return cls.classes[category].index(str(class_name))

    @classmethod
    def _print_frequencies(cls):
        for category, value in cls.frequencies.items():
            print(f"\n{category} ({len(value.keys())})")
            for k, v in sorted(value.items()):
                print(f"\t{k}: {v}")

    def __getitem__(self, index):
        """
        Retrieve a sample by index

        Parameters
        ----------
        index : int

        Returns
        -------
        img : FloatTensor
        target : dict
            Dict with all the labels
        """
        # Fetch images
        img = pil_loader(self.filenames[index])

        # Fetch the target values and store them into a dict{category:index}
        target = self.values[index, :]
        target = {c: self._name_to_idx(c, t) for c, t in zip(self.categories, target)}

        if self.transform is not None:
            img = self.transform(img)
        if self.target_transform is not None:
            target = self.target_transform(target)
        return img, target

    def __len__(self):
        return len(self.filenames)
